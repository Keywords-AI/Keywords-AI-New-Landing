---
title: "How to optimize LLM performance in startups"
date: November 22, 2024
author: Hendrix
cover: https://keywordsai-static.s3.us-east-1.amazonaws.com/landing/blog/optimize_llm-performance/cover.png
---

## How to optimize LLM performance in startups

Want to supercharge your startup with AI? Here's how to get the most out of LLMs without breaking the bank:

1. Choose the right model for each task  
2. Write clear, concise prompts  
3. Use caching to speed up responses  
4. Implement Retrieval-Augmented Generation (RAG)  
5. Fine-tune smaller models for specific jobs  
6. Monitor usage and costs closely  
7. Route queries to cheaper models first  
8. Mix different models for various tasks

### Key benefits:

- Cut costs by up to 80%  
- Boost response speed  
- Improve answer accuracy

### Key LLM Performance Metrics

To get the most out of LLMs in your startup, you need to track their performance. Here are the key metrics to watch:

**Speed**  
How fast does your LLM respond? This is crucial for user experience. Slow responses = frustrated users.

**Output Volume**  
This measures how much content your LLM can produce. It's vital for tasks like content creation or customer support.

**Accuracy**  
Is your LLM giving correct answers? This builds user trust.

| Metric | Measures | Why It's Important |
| --- | --- | --- |
| Answer Relevancy | Does it address the input? | Ensures useful responses |
| Correctness | Is it factually correct? | Builds trust |
| Hallucination | Does it make stuff up? | Prevents misinformation |

**Task-Specific Metrics**  
You might need custom metrics depending on your LLM's use. For summarization, you'd check how well it captures key points. Learn how to create custom evaluations [here](https://docs.keywordsai.co/features/evaluation/llm-as-a-judge).

**Responsible Metrics**  
These check for bias or toxic content in LLM outputs. It's about keeping your AI ethical.

Why track all this? It helps you spot problems early and improve your LLM. The metrics you focus on depend on your LLM's purpose. A chatbot might prioritize speed and relevancy, while a content generator might focus on output volume and accuracy.

## Picking the Best LLM for Your Startup

Choosing an LLM for your startup isn't just about grabbing the hottest or cheapest option. You need to match the model to your specific needs.

### 1. Abilities

LLMs have different strengths. Some are all-rounders, others are specialists.

- O1-preview: Great for complex reasoning  
- Claude 3.5 Sonnet: Great for handling complex tasks and fast response speed  
- Gemini 1.5 Pro: Handles multiple input types

What does your startup NEED? A Swiss Army knife or a laser-focused tool?

### 2. Cost

LLMs can burn through cash fast. Here's a quick price comparison:

| Model | Price |
| --- | --- |
| GPT-4o | $2.50 / 1M input tokens, $10.00 / 1M output tokens |
| o1-preview | $15.00 / 1M input tokens, $60.00 / 1M output tokens |
| Claude 3.5 Sonnet | $3.00 / 1M input tokens, $15.00 / 1M output tokens |
| Gemini 1.5 Pro | $2.50 / 1M input tokens, $10.00 / 1M output tokens |
| Cohere Command R+ | $2.50 / 1M input tokens, $10.00 / 1M output tokens |

But remember: Cheaper isn't always better. A pricier model might save you money if it's more accurate or efficient.

### 3. Ease of Use

Can you plug it in and go? Look at:

- API compatibility: You can use [an AI gateway](https://docs.keywordsai.co/get-started/llm-inference) to solve this easily.  
- Community support

### 4. Performance

Key metrics to watch:

- Speed (latency)  
- Accuracy  
- Output quality

For chat apps, aim for under 200ms to first token. Users hate waiting.

## Writing Better Prompts

Want great results from LLMs? It's all about the prompts. Here's how to craft them:

### Be specific and clear

Vague prompts = vague outputs. Instead of "What's a good marketing strategy?", try:

"Create a social media plan for a SaaS startup targeting small businesses. Include content ideas for Facebook, Twitter, and LinkedIn, posting frequency, and 3 campaign concepts."

### Provide context

"You're a financial advisor helping a 35-year-old software engineer with $50k in savings. Recommend an investment strategy for a house down payment in 5 years."

### Use examples

Show, don’t just tell. Few-shot example:

"Rewrite these sentences to be more engaging:

1. Original: The meeting is at 2 PM. Rewrite: Let’s sync up at 2 PM for a power hour of brainstorming!  
2. Original: Please submit your report by Friday. Rewrite: Friday’s the big day! Can’t wait to dive into your report.  
3. Original: The new policy takes effect next month. Rewrite: [Your rewrite here]"

### Break down complex tasks

1. "Summarize the key points of this AI ethics research paper."  
2. "Identify potential ethical concerns for AI startups based on the summary."  
3. "Suggest 3 practical guidelines for AI startups to address these concerns."

### Use output primers

"Create a product description for our new project management software. Structure:

Headline:  
One-sentence summary:  
Key features (bullet points):  
Pricing:  
Call to action:"

### Experiment and refine

Not getting what you need? Tweak your prompts. Adjust wording, add context, or break tasks into smaller steps.

### Collaborate on prompts with the team

Use a prompt management tool to collaborate and iterate more easily.

## Using Retrieval-Augmented Generation (RAG)

RAG is a big deal for startups wanting better LLMs. It mixes info retrieval with text generation, letting LLMs use external knowledge for more accurate answers.

### How RAG Works

RAG has two main steps:

- It finds relevant info based on what you ask  
- The LLM uses this info to create an answer

| Part | What It Does | Tips |
| --- | --- | --- |
| Retrieval | Finds relevant data | Use smart search methods |
| Augmentation | Adds context to prompts | Make sure added info fits |
| Generation | Makes final output | Balance LLM skills and added data |

## Improving Performance with Caching

Caching is a game-changer for startups using LLMs. It’s like a cheat sheet for your AI, storing answers to questions it’s seen before.

### Benefits:

- Speed Boost: Response times drop dramatically  
- Cost Savings: Up to 90% lower API costs  
- Better UX: Faster answers = happier users

Semantic caching is the smart upgrade—faster for similar questions.

Start here: [LLM caching](https://docs.keywordsai.co/features/generation/caches)

Real-world win: [Anthropic](https://www.anthropic.com/) saw a 90% cost cut and 85% speed boost.

Keep it fresh: Update cache regularly to prevent outdated responses.

## Customizing LLMs for Specific Jobs

Off-the-shelf LLMs not cutting it? Time to customize.

### When to Customize

- Unique business tasks  
- Industry-specific language  
- Poor general model performance

### Fine-Tuning Steps

1. Choose a pre-trained model  
2. Prepare your training data  
3. Adjust parameters  
4. Train  
5. Test  
6. Deploy

### Real-World Wins

| Company | Model | Result |
| --- | --- | --- |
| Google | Med-PaLM 2 | 86.5% on US Medical Licensing Exam |
| Bloomberg | BloombergGPT | Top performance on financial tasks |

### Alternatives

| Method | Up-front Cost | Ongoing Cost |
| --- | --- | --- |
| Prompt Engineering | Low | Low |
| RAG | Medium | Medium |
| Fine-Tuning | High | Low |

Tips:  
- Start small  
- Use clean data  
- Monitor results  
- Retrain as needed

## FAQs

### Are LLM benchmarks reliable?

They're helpful, but not the full picture:

- Don’t show real-world results  
- Become outdated quickly  
- Still allow for error

To truly know your LLM:

1. Test on your actual tasks  
2. Monitor performance continuously  
3. Stay current on benchmarks

> "As LLMs become part of business workflows, making sure they’re reliable is crucial." – Anjali Chaudhary

Example: Dataherald saved money using tools like [Helicone](https://www.helicone.ai/) and [LangSmith](https://smith.langchain.com/).

Bottom line: Benchmarks are a start. Ongoing checks and improvements are the key.
