{
  "timestamp": "March 27, 2025",
  "type": "MODELS",
  "subtitle": "",
  "title": "Meet Inference.net â€“ A Faster, Cheaper Way to Run Open-Source LLMs",
  "description": "Run open-source LLMs faster and cheaper with Inference.net. Explore pricing, performance benchmarks, and easy integration options for developers and teams.",
  "image": "https://keywordsai-static.s3.us-east-1.amazonaws.com/landing/blog/inference-net/cover.jpg"
}
